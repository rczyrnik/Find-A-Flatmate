{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INCLUDES:\n",
    "\n",
    "# LINEAR REGRESSION\n",
    "\n",
    "# RANDOM FOREST REGRESSOR\n",
    "\n",
    "# GRADIENT BOOSTING REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import my_pickle as mp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import my_resample as ms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_binary(lst, cutoff=1):\n",
    "    return [1 if x > cutoff else 0 for x in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mp.unjson_it('data_X')\n",
    "y = mp.unjson_it('data_y')['convo_length']\n",
    "text_similarity_df = mp.unjson_it('data_text_similarity')\n",
    "X['count_similarity'] = text_similarity_df['count_similarity']\n",
    "X['tfidf_similarity'] = text_similarity_df['tfidf_similarity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE DATA\n",
    "\n",
    "same train test split, resample, and scaling for everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.as_matrix(), y.as_matrix(), random_state=17)\n",
    "\n",
    "# resample\n",
    "X_train, y_train = ms.oversample(X_train, y_train, .9)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_train, y_train))\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERT TO BINARY AND GET ACURACY ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_binary = convert_to_binary(y_pred,3)\n",
    "y_test_binary = convert_to_binary(y_test,3)\n",
    "\n",
    "print(\"\\nMETRICS\")\n",
    "print(\"Model recall: {}\".format(recall_score(y_test_binary, y_pred_binary)))\n",
    "print(\"Model precision: {}\".format(precision_score(y_test_binary, y_pred_binary)))\n",
    "print(\"Model accuracy: {}\".format(model.score(X_test, y_test_binary)))\n",
    "\n",
    "print (\"\\nCONFUSION MATRIX\")\n",
    "print (confusion_matrix(y_test_binary, y_pred_binary))\n",
    "print (\"\\nkey:\")\n",
    "print (\" TN   FP \")\n",
    "print (\" FN   TP \")\n",
    "\n",
    "# return recall_score(y_test_binary, y_pred_binary), precision_score(y_test_binary, y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_feature_importances():\n",
    "    # show feature importances\n",
    "    pd.options.display.float_format = '{:,.2f}'.format\n",
    "    feature_df = pd.DataFrame([X.columns, model.coef_]).T\n",
    "    feature_df.columns = ['feature','coefficient']\n",
    "    feature_df['abs_value'] = feature_df.coefficient.apply(abs)\n",
    "    feature_df['sign'] = feature_df.coefficient/feature_df.abs_value\n",
    "    return feature_df.sort_values('abs_value', ascending=False)\n",
    "display_feature_importances().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESAMPLE AS A HYPERPARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_together(X_df,resamp,cutoff):\n",
    "    # GET DATA\n",
    "    y = X_df.convo_length\n",
    "    X = X_df.drop(['convo_length'], axis=1)\n",
    "\n",
    "    # TRAIN TEST SPLIT\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.as_matrix(), y.as_matrix(), random_state=17)\n",
    "\n",
    "    # RESAMPLE\n",
    "    X_train, y_train = ms.oversample(X_train, y_train, resamp)\n",
    "\n",
    "    # SCALE DATA\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # fit model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "#     print(model.score(X_train, y_train))\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred_binary = [1 if x > cutoff else 0 for x in y_pred]\n",
    "    y_test_binary = [1 if x > cutoff else 0 for x in y_test]\n",
    "    \n",
    "    return recall_score(y_test_binary, y_pred_binary), precision_score(y_test_binary, y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = []\n",
    "precision = []\n",
    "x_values = np.arange(.01,10,.01)\n",
    "for x in x_values:\n",
    "    r,p = all_together(X_df,x, 1)\n",
    "    recall.append(r)\n",
    "    precision.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_values, recall)\n",
    "ax.plot(x_values, precision)\n",
    "ax.set_title('RECALL AND PRECISION')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GET DATA\n",
    "y = X_df.convo_length\n",
    "X = X_df.drop(['convo_length','response'], axis=1)\n",
    "\n",
    "# TRAIN TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.as_matrix(), y.as_matrix(), random_state=17)\n",
    "\n",
    "# RESAMPLE\n",
    "# X_train, y_train = ms.oversample(X_train, y_train, .5)\n",
    "\n",
    "# SCALE DATA\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# fit model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get feature importances\n",
    "feature_importances = np.argsort(model.feature_importances_)\n",
    "top_n = 10 #len(X.columns)\n",
    "print(\"\\nFEATURE RANKINGS\")\n",
    "for n in range(top_n):\n",
    "    print(n+1, '\\t',X.columns[feature_importances[-n-1]], '\\t',sorted(model.feature_importances_)[-n-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_cutoff(cutoff, lotsa = True):\n",
    "    y_pred_binary = [1 if x > cutoff else 0 for x in y_pred]\n",
    "    y_test_binary = [1 if x > cutoff else 0 for x in y_test]\n",
    "\n",
    "    if lotsa:\n",
    "        print(\"\\nMETRICS\")\n",
    "        print(\"Model recall: {}\".format(recall_score(y_test_binary, y_pred_binary)))\n",
    "        print(\"Model precision: {}\".format(precision_score(y_test_binary, y_pred_binary)))\n",
    "        print(\"Model accuracy: {}\".format(model.score(X_test, y_test_binary)))\n",
    "\n",
    "        print (\"\\nCONFUSION MATRIX\")\n",
    "        print (confusion_matrix(y_test_binary, y_pred_binary))\n",
    "        print (\"\\nkey:\")\n",
    "        print (\" TN   FP \")\n",
    "        print (\" FN   TP \")\n",
    "    \n",
    "    return recall_score(y_test_binary, y_pred_binary), precision_score(y_test_binary, y_pred_binary)\n",
    "\n",
    "change_cutoff(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_recall_precision():\n",
    "    recall = []\n",
    "    precision = []\n",
    "    x_values = np.arange(0,10,.1)\n",
    "    for cutoff in x_values:\n",
    "        r,p = change_cutoff(cutoff,False)\n",
    "        recall.append(r)\n",
    "        precision.append(p)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x_values, recall)\n",
    "    ax.plot(x_values, precision)\n",
    "    ax.set_title('RECALL AND PRECISION')\n",
    "    plt.show()\n",
    "plot_recall_precision()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# GRADIENT BOOSTING REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.as_matrix(), y.as_matrix(), random_state=17)\n",
    "\n",
    "# RESAMPLE\n",
    "X_train, y_train = ms.oversample(X_train, y_train, .5)\n",
    "\n",
    "# SCALE DATA\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# fit model\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importances\n",
    "feature_importances = np.argsort(model.feature_importances_)\n",
    "top_n = 10 #len(X.columns)\n",
    "print(\"\\nFEATURE RANKINGS\")\n",
    "for n in range(top_n):\n",
    "    print(n+1, '\\t',X.columns[feature_importances[-n-1]], '\\t',sorted(model.feature_importances_)[-n-1],'\\t',feature_importances[-n-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances[-4:]\n",
    "# X.columns[feature_importances[-4:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_cutoff(cutoff, lotsa = True):\n",
    "    y_pred_binary = [1 if x > cutoff else 0 for x in y_pred]\n",
    "    y_test_binary = [1 if x > cutoff else 0 for x in y_test]\n",
    "\n",
    "    if lotsa:\n",
    "        print(\"\\nMETRICS\")\n",
    "        print(\"Model recall: {}\".format(recall_score(y_test_binary, y_pred_binary)))\n",
    "        print(\"Model precision: {}\".format(precision_score(y_test_binary, y_pred_binary)))\n",
    "        print(\"Model accuracy: {}\".format(model.score(X_test, y_test_binary)))\n",
    "\n",
    "        print (\"\\nCONFUSION MATRIX\")\n",
    "        print (confusion_matrix(y_test_binary, y_pred_binary))\n",
    "        print (\"\\nkey:\")\n",
    "        print (\" TN   FP \")\n",
    "        print (\" FN   TP \")\n",
    "    \n",
    "    return recall_score(y_test_binary, y_pred_binary), precision_score(y_test_binary, y_pred_binary)\n",
    "\n",
    "change_cutoff(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_recall_precision():\n",
    "    recall = []\n",
    "    precision = []\n",
    "    x_values = np.arange(0,10,.1)\n",
    "    for cutoff in x_values:\n",
    "        r,p = change_cutoff(cutoff,False)\n",
    "        recall.append(r)\n",
    "        precision.append(p)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x_values, recall)\n",
    "    ax.plot(x_values, precision)\n",
    "    ax.set_title('RECALL AND PRECISION')\n",
    "    plt.show()\n",
    "plot_recall_precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_partial_dependence(model, X_train, feature_importances[-6:], X.columns, n_jobs=-1,figsize = (16,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_partial_dependence(model, X_train, [71]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
