{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INCLUDES:\n",
    "\n",
    "# LOGISTIC REGRESSION\n",
    "\n",
    "# DECISION TREE CLASSIFIER\n",
    "\n",
    "# RANDOM FOREST CLASSIFIER\n",
    "\n",
    "# GRADIENT BOOSTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "import my_pickle as mp\n",
    "import my_features as mf\n",
    "import my_resample as ms\n",
    "# from my_resample import div_count_pos_neg, undersample, oversample\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = mp.unjson_it('data_user_active')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.active\n",
    "TF = {True:1, False:0}\n",
    "y = y.map(TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(['active'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.fillna(X.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mp.json_it(X,'save_the_filled_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = mp.unjson_it('save_the_filled_array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.amenities = X.amenities.apply(lambda x: len(x) if isinstance(x,list) else 0)\n",
    "X.hobbies = X.hobbies.apply(lambda x: len(x) if isinstance(x,list) else 0)\n",
    "X.neighborhoods = X.neighborhoods.apply(lambda x: len(x) if isinstance(x,list) else 0)\n",
    "X.location = X.location.apply(lambda x: 1 if isinstance(x,list) else 0)\n",
    "X['len_about'] = X.about.apply(len)\n",
    "X['has_about'] = X['len_about'].apply(lambda x: x>0)\n",
    "X['has_about']= X['has_about'].map(TF)\n",
    "X.college = X.college.apply(lambda x: 1 if isinstance(x,str) else 0)\n",
    "X.hometownCity = X.hometownCity.apply(lambda x: 1 if isinstance(x,str) else 0)\n",
    "X.hometownCountry = X.hometownCountry.apply(lambda x: 1 if isinstance(x,str) else 0)\n",
    "X.hometownState = X.hometownState.apply(lambda x: 1 if isinstance(x,str) else 0)\n",
    "X.work = X.work.apply(lambda x: 1 if isinstance(x,str) else 0)\n",
    "\n",
    "TF = {True:1, False:0}\n",
    "TF_col = ['facebookId','has_about','has_room','linkedinId','picture','has_about']\n",
    "for col in TF_col:\n",
    "    X[col]= X[col].map(TF)\n",
    "to_drop = ['type','uid','about','metro','picture','facebookId','linkedinId']\n",
    "X = X.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('picture', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['linkedinId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smokingOk</th>\n",
       "      <th>term</th>\n",
       "      <th>updated</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.64896</td>\n",
       "      <td>1515795357071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>1515728861473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515777832739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515762098553</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1515758318235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515798525964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>0</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1515760314351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>1</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515727237973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>1</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515727061594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>1</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515732632000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>1</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515777046752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>1</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1515779090669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>1</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515750554241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>1</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515776800794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>1</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515795232425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>0</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1515782312021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>0</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1515758044996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>0</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515759406284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>1</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1515770249661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>0</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>1515734176955</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>1</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515763776849</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10015</th>\n",
       "      <td>1</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515725729700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10016</th>\n",
       "      <td>0</td>\n",
       "      <td>11.64896</td>\n",
       "      <td>1515752595865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10017</th>\n",
       "      <td>1</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>1515796233068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10018</th>\n",
       "      <td>1</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1515725135619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10019</th>\n",
       "      <td>1</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>1515748096813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>0</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>1515758960578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10020</th>\n",
       "      <td>1</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1515773472354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10021</th>\n",
       "      <td>1</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1515724627691</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10022</th>\n",
       "      <td>0</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>1515799020505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>0</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>1515734149941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>0</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515760618953</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>0</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1515754713641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>0</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>1515754323969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>0</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1515790638198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>0</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1515785806717</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>1</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515763176965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1515767786737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1515766197925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>0</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>1515794068768</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>0</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515733724953</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>1</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>1515733594535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>0</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1515733011582</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>0</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515780174850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>1</td>\n",
       "      <td>11.64896</td>\n",
       "      <td>1515801089421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>0</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515782382675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>1</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>1515794444718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>0</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515767754595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>1</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>1515753047983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>1515730883214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1515754027715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>1</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>1515752580620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>0</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515748094170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>0</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515771961373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>1</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515734628282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "      <td>11.64896</td>\n",
       "      <td>1515802531041</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515728601057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>1515733736249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515734471542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>1515771222031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25738 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       smokingOk      term        updated  work\n",
       "0              1  11.64896  1515795357071     1\n",
       "1              1   8.00000  1515728861473     0\n",
       "10             1  12.00000  1515777832739     1\n",
       "100            0  12.00000  1515762098553     1\n",
       "1000           1   6.00000  1515758318235     0\n",
       "10000          0  12.00000  1515798525964     1\n",
       "10001          0   6.00000  1515760314351     0\n",
       "10002          1  12.00000  1515727237973     0\n",
       "10003          1  12.00000  1515727061594     0\n",
       "10004          1  12.00000  1515732632000     1\n",
       "10005          1  12.00000  1515777046752     0\n",
       "10006          1   6.00000  1515779090669     0\n",
       "10007          1  12.00000  1515750554241     0\n",
       "10008          1  12.00000  1515776800794     1\n",
       "10009          1  12.00000  1515795232425     1\n",
       "1001           0   3.00000  1515782312021     1\n",
       "10010          0   3.00000  1515758044996     1\n",
       "10011          0  12.00000  1515759406284     1\n",
       "10012          1   6.00000  1515770249661     1\n",
       "10013          0  24.00000  1515734176955     1\n",
       "10014          1  12.00000  1515763776849     0\n",
       "10015          1  12.00000  1515725729700     1\n",
       "10016          0  11.64896  1515752595865     1\n",
       "10017          1   4.00000  1515796233068     0\n",
       "10018          1   6.00000  1515725135619     0\n",
       "10019          1  24.00000  1515748096813     1\n",
       "1002           0  24.00000  1515758960578     0\n",
       "10020          1   6.00000  1515773472354     1\n",
       "10021          1   6.00000  1515724627691     0\n",
       "10022          0  10.00000  1515799020505     1\n",
       "...          ...       ...            ...   ...\n",
       "9972           0  15.00000  1515734149941     1\n",
       "9973           0  12.00000  1515760618953     0\n",
       "9974           0   6.00000  1515754713641     0\n",
       "9975           0  24.00000  1515754323969     0\n",
       "9976           0   6.00000  1515790638198     1\n",
       "9977           0   5.00000  1515785806717     0\n",
       "9978           1  12.00000  1515763176965     0\n",
       "9979           1   1.00000  1515767786737     1\n",
       "998            0   6.00000  1515766197925     1\n",
       "9980           0  13.00000  1515794068768     0\n",
       "9981           0  12.00000  1515733724953     0\n",
       "9982           1   4.00000  1515733594535     1\n",
       "9983           0   6.00000  1515733011582     1\n",
       "9984           0  12.00000  1515780174850     1\n",
       "9985           1  11.64896  1515801089421     1\n",
       "9986           0  12.00000  1515782382675     0\n",
       "9987           1  11.00000  1515794444718     0\n",
       "9988           0  12.00000  1515767754595     0\n",
       "9989           1  24.00000  1515753047983     0\n",
       "999            0  11.00000  1515730883214     0\n",
       "9990           1   1.00000  1515754027715     1\n",
       "9991           1   6.00000  1515752580620     1\n",
       "9992           0  12.00000  1515748094170     0\n",
       "9993           0  12.00000  1515771961373     1\n",
       "9994           1  12.00000  1515734628282     1\n",
       "9995           1  11.64896  1515802531041     0\n",
       "9996           1  12.00000  1515728601057     0\n",
       "9997           0   7.00000  1515733736249     0\n",
       "9998           0  12.00000  1515734471542     1\n",
       "9999           1  12.00000  1515771222031     1\n",
       "\n",
       "[25738 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[:,40:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE DATA\n",
    "\n",
    "same train test split, resample, and scaling for everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.as_matrix(), y.as_matrix(), random_state=17)\n",
    "\n",
    "# resample\n",
    "X_train, y_train = ms.oversample(X_train, y_train, .5)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# make fake data\n",
    "pred_all_0 = [0]*len(y_test)\n",
    "pred_all_1 = [1]*len(y_test)\n",
    "pred_50_50 = np.random.choice([0,1], size=len(y_test))\n",
    "pred_90_10 = np.random.choice([0,1], size=len(y_test), p=[.9,.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def do_stuff(model):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_full.as_matrix(), y.as_matrix(), random_state=17)\n",
    "\n",
    "#     X_train, y_train = ms.oversample(X_train, y_train, .5)\n",
    "\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     print(\"\\nMETRICS\")\n",
    "#     print(\"Model recall: {}\".format(recall_score(y_test, y_pred)))\n",
    "#     print(\"Model precision: {}\".format(precision_score(y_test, y_pred)))\n",
    "#     print(\"Model accuracy: {}\".format(model.score(X_test, y_test)))\n",
    "\n",
    "#     pred_all_0 = [0]*len(y_test)\n",
    "#     pred_all_1 = [1]*len(y_test)\n",
    "#     pred_50_50 = np.random.choice([0,1], size=len(y_test))\n",
    "#     pred_90_10 = np.random.choice([0,1], size=len(y_test), p=[.9,.1])\n",
    "\n",
    "#     print (\"\\nCONFUSION MATRIX\")\n",
    "#     print (confusion_matrix(y_test, y_pred))\n",
    "#     print (\"\\nkey:\")\n",
    "#     print (\" TN   FP \")\n",
    "#     print (\" FN   TP \")\n",
    "\n",
    "#     print(\"\\nRECALL AND ACCURACY FOR DIFFERNET MODELS\")\n",
    "#     print(\"recall     \\t precision   \\tmodel\")\n",
    "#     print(recall_score(y_test, y_pred), '\\t',precision_score(y_test, y_pred), \"my model\")\n",
    "#     print(recall_score(y_test, pred_all_0),'\\t','\\t', precision_score(y_test, pred_all_0), \"\\t\\tpredict all zero\")\n",
    "#     print(recall_score(y_test, pred_all_1),'\\t','\\t', precision_score(y_test, pred_all_1), \"predict all one\")\n",
    "#     print(recall_score(y_test, pred_50_50),'\\t', precision_score(y_test, pred_50_50), \"predict 50-50\")\n",
    "#     print(recall_score(y_test, pred_90_10), precision_score(y_test, pred_90_10), \"predict 90-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_importances_trees():\n",
    "    # show feature importances\n",
    "    feature_df = pd.DataFrame([X.columns, model.feature_importances_]).T\n",
    "    feature_df.columns = ['feature','value']\n",
    "    return feature_df.sort_values('value', ascending=False)\n",
    "             \n",
    "def display_metrics():\n",
    "    print(\"\\nMETRICS\")\n",
    "    print(\"Model recall: {}\".format(recall_score(y_test, y_pred)))\n",
    "    print(\"Model precision: {}\".format(precision_score(y_test, y_pred)))\n",
    "    print(\"Model accuracy: {}\".format(model.score(X_test, y_test)))\n",
    "\n",
    "    print (\"\\nCONFUSION MATRIX\")\n",
    "    print (confusion_matrix(y_test, y_pred))\n",
    "    print (\"\\nkey:\")\n",
    "    print (\" TN   FP \")\n",
    "    print (\" FN   TP \")\n",
    "\n",
    "    print(\"\\nRECALL AND ACCURACY FOR DIFFERNET MODELS\")\n",
    "    print(\"recall     \\t precision   \\tmodel\")\n",
    "    print(recall_score(y_test, y_pred), '\\t',precision_score(y_test, y_pred), \"my model\")\n",
    "    print(recall_score(y_test, pred_all_0),'\\t','\\t', precision_score(y_test, pred_all_0), \"\\t\\tpredict all zero\")\n",
    "    print(recall_score(y_test, pred_all_1),'\\t','\\t', precision_score(y_test, pred_all_1), \"predict all one\")\n",
    "    print(recall_score(y_test, pred_50_50),'\\t', precision_score(y_test, pred_50_50), \"predict 50-50\")\n",
    "    print(recall_score(y_test, pred_90_10), precision_score(y_test, pred_90_10), \"predict 90-10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "METRICS\n",
      "Model recall: 0.5185449358059915\n",
      "Model precision: 0.5774424146147736\n",
      "Model accuracy: 0.8124320124320125\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[4501  532]\n",
      " [ 675  727]]\n",
      "\n",
      "key:\n",
      " TN   FP \n",
      " FN   TP \n",
      "\n",
      "RECALL AND ACCURACY FOR DIFFERNET MODELS\n",
      "recall     \t precision   \tmodel\n",
      "0.518544935806 \t 0.577442414615 my model\n",
      "0.0 \t \t 0.0 \t\tpredict all zero\n",
      "1.0 \t \t 0.217871017871 predict all one\n",
      "0.48002853067 \t 0.214126630608 predict 50-50\n",
      "0.108416547789 0.223858615611 predict 90-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gandalf/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>created</td>\n",
       "      <td>0.231714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>activeAt</td>\n",
       "      <td>0.118442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>updated</td>\n",
       "      <td>0.0762462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>location</td>\n",
       "      <td>0.0712661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>available</td>\n",
       "      <td>0.0586081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature      value\n",
       "9     created   0.231714\n",
       "2    activeAt   0.118442\n",
       "42    updated  0.0762462\n",
       "27   location  0.0712661\n",
       "5   available  0.0586081"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = RandomForestClassifier(max_depth=50, max_features=None, min_samples_leaf=3, n_estimators=100, n_jobs=-1)\n",
    "# do_stuff(model)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# show metrics\n",
    "display_metrics()\n",
    "\n",
    "# show importances\n",
    "display_importances_trees().head(5)\n",
    "\n",
    "# feature_importances = np.argsort(model.feature_importances_)\n",
    "# top_n = 20\n",
    "# print(\"\\nFEATURE RANKINGS\")\n",
    "# for n in range(top_n):\n",
    "#     print(n+1, '\\t',X.columns[feature_importances[-n-1]], '\\t',sorted(model.feature_importances_)[-n-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-1e7015fb7aa2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-1e7015fb7aa2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    F1: 2pr/p+r\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIENT BOOSTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "METRICS\n",
      "Model recall: 0.9308131241084165\n",
      "Model precision: 0.4719710669077758\n",
      "Model accuracy: 0.7580419580419581\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[3573 1460]\n",
      " [  97 1305]]\n",
      "\n",
      "key:\n",
      " TN   FP \n",
      " FN   TP \n",
      "\n",
      "RECALL AND ACCURACY FOR DIFFERNET MODELS\n",
      "recall     \t precision   \tmodel\n",
      "0.930813124108 \t 0.471971066908 my model\n",
      "0.0 \t \t 0.0 \t\tpredict all zero\n",
      "1.0 \t \t 0.217871017871 predict all one\n",
      "0.48002853067 \t 0.214126630608 predict 50-50\n",
      "0.108416547789 0.223858615611 predict 90-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gandalf/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>created</td>\n",
       "      <td>0.354717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>activeAt</td>\n",
       "      <td>0.129431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>available</td>\n",
       "      <td>0.0578716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>updated</td>\n",
       "      <td>0.044227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>neighborhoods</td>\n",
       "      <td>0.0336375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature      value\n",
       "9         created   0.354717\n",
       "2        activeAt   0.129431\n",
       "5       available  0.0578716\n",
       "42        updated   0.044227\n",
       "30  neighborhoods  0.0336375"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# show metrics\n",
    "display_metrics()\n",
    "\n",
    "# show importances\n",
    "display_importances_trees().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "METRICS\n",
      "Model recall: 0.48288159771754635\n",
      "Model precision: 0.498894620486367\n",
      "Model accuracy: 0.7816627816627817\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[4353  680]\n",
      " [ 725  677]]\n",
      "\n",
      "key:\n",
      " TN   FP \n",
      " FN   TP \n",
      "\n",
      "RECALL AND ACCURACY FOR DIFFERNET MODELS\n",
      "recall     \t precision   \tmodel\n",
      "0.482881597718 \t 0.498894620486 my model\n",
      "0.0 \t \t 0.0 \t\tpredict all zero\n",
      "1.0 \t \t 0.217871017871 predict all one\n",
      "0.48002853067 \t 0.214126630608 predict 50-50\n",
      "0.108416547789 0.223858615611 predict 90-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gandalf/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>created</td>\n",
       "      <td>0.45375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>activeAt</td>\n",
       "      <td>0.0529474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>location</td>\n",
       "      <td>0.0490401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>updated</td>\n",
       "      <td>0.036997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>maxCost</td>\n",
       "      <td>0.0354758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature      value\n",
       "9    created    0.45375\n",
       "2   activeAt  0.0529474\n",
       "27  location  0.0490401\n",
       "42   updated   0.036997\n",
       "28   maxCost  0.0354758"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# show metrics\n",
    "display_metrics()\n",
    "\n",
    "# show importances\n",
    "display_importances_trees().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "do_stuff(model)\n",
    "\n",
    "feature_coefficients = np.argsort(model.coef_)\n",
    "top_n = 10\n",
    "# print(\"\\nFEATURE RANKINGS\")\n",
    "# for n in range(top_n):\n",
    "#     print(n+1, '\\t',X.columns[feature_coefficients[-n-1]], '\\t',sorted(model.feature_importances_)[-n-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame([X.columns,model.coef_[0]]).T\n",
    "results_df.columns = ['feature','coefficients']\n",
    "results_df['abs_val'] = results_df.coefficients.apply(abs)\n",
    "results_df['sign'] = results_df.coefficients.apply(lambda s: s>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df.head().sort_values('abs_val', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_grid_search(X, y):\n",
    "    '''\n",
    "    X as 2d numpy array\n",
    "    y as 1d numpy array\n",
    "    \n",
    "    PARAMETERS\n",
    "    n_estimators: The number of trees in the forest\n",
    "    criterion: gini or entropy\n",
    "    max_features: The number of features to consider when looking for the best split\n",
    "        If int, then consider max_features features at each split.\n",
    "        If float, then max_features is a percentage and int(max_features * n_features) features are considered at each split.\n",
    "        If “auto”, then max_features=sqrt(n_features).\n",
    "        If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).\n",
    "        If “log2”, then max_features=log2(n_features).\n",
    "        If None, then max_features=n_features.\n",
    "    max_depth: The maximum depth of the tree\n",
    "    n_jobs: The number of jobs to run in parallel for both fit and predict. If -1, then the number of jobs is set to the number of cores.\n",
    "    '''\n",
    "    \n",
    "    # Split it up into our training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    # resample\n",
    "    X_train, y_train = ms.oversample(X_train.as_matrix(), y_train.as_matrix(), .5)\n",
    "    \n",
    "    # Initalize our model here\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    # Here are the params we are tuning\n",
    "    param_grid = {'max_features' : [None],\n",
    "                  'n_estimators' : [50,100,1000],\n",
    "                  'max_depth': [50],\n",
    "                  'min_samples_leaf': [3]\n",
    "                  }\n",
    "\n",
    "    # Plug in our model, params dict, and the number of jobs, then .fit()\n",
    "    gs_cv = GridSearchCV(model, param_grid, n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "    # return the best score and the best params\n",
    "    return gs_cv.best_score_, gs_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = RandomForestClassifier(max_depth=50, max_features=None, min_samples_leaf=3, n_estimators=100, n_jobs=-1)\n",
    "fit_model(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n = do_grid_search(X, y)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = LogisticRegression()\n",
    "fit_model(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print (\"    Decision Tree:       \", get_scores(DecisionTreeClassifier, X_train, X_test, y_train, y_test))\n",
    "print (\"    Naive Bayes:         \", get_scores(MultinomialNB, X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the standard deviation for feature importances across all trees\n",
    "\n",
    "n = len(X.columns)\n",
    "\n",
    "#importances = forest_fit.feature_importances_[:n]\n",
    "importances = model.feature_importances_[:n]\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features = list(X.columns[indices])\n",
    "\n",
    "# print(\"Feature ranking:\")\n",
    "# for f in range(n):\n",
    "#     print(\"%d. %s (%f)\" % (f + 1, features[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(n), importances[indices], yerr=std[indices], color=\"r\", align=\"edge\", width = -.9)\n",
    "plt.xticks(range(n), features, rotation=-75)\n",
    "plt.xlim([-1, n])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try modifying the number of trees, graph results\n",
    "num_trees = range(5, 50, 5)\n",
    "accuracies = []\n",
    "for n in num_trees:\n",
    "    tot = 0\n",
    "    for i in range(5):\n",
    "        rf = RandomForestClassifier(n_estimators=n)\n",
    "        rf.fit(X_train, y_train)\n",
    "        tot += rf.score(X_test, y_test)\n",
    "    accuracies.append(tot / 5)\n",
    "plt.plot(num_trees, accuracies)\n",
    "plt.xlabel=\"num_trees\"\n",
    "plt.ylabel=\"accuracy\"\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modifying the max features parameter\n",
    "for nn in range(10):\n",
    "    num_features = range(2, len(X.columns))\n",
    "    accuracies = []\n",
    "    for n in num_features:\n",
    "        tot = 0\n",
    "        for i in range(5):\n",
    "            rf = RandomForestClassifier(max_features=n)\n",
    "            rf.fit(X_train, y_train)\n",
    "            tot += rf.score(X_test, y_test)\n",
    "        accuracies.append(tot / 5)\n",
    "    plt.plot(num_features, accuracies)\n",
    "    plt.xlabel=\"num_features\"\n",
    "    plt.ylabel=\"accuracy\"\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run all the other classifiers that we have learned so far in class\n",
    "def get_scores(classifier, X_train, X_test, y_train, y_test, **kwargs):\n",
    "    model = classifier(**kwargs)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    return model.score(X_test, y_test), \\\n",
    "           precision_score(y_test, y_predict), \\\n",
    "           recall_score(y_test, y_predict)\n",
    "\n",
    "print (\"    Model,                Accuracy, Precision, Recall\")\n",
    "print (\"    Random Forest:       \", get_scores(RandomForestClassifier, X_train, X_test, y_train, y_test, n_estimators=25, max_features=5))\n",
    "print (\"    Logistic Regression: \", get_scores(LogisticRegression, X_train, X_test, y_train, y_test))\n",
    "print (\"    Decision Tree:       \", get_scores(DecisionTreeClassifier, X_train, X_test, y_train, y_test))\n",
    "print (\"    Naive Bayes:         \", get_scores(MultinomialNB, X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc(X, y, clf_class, title, **kwargs):\n",
    "# def plot_roc(X, y, clf_class, kwargs):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    kf = KFold(len(y), n_folds=5, shuffle=True)\n",
    "    y_prob = np.zeros((len(y),2))\n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    all_tpr = []\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        # Predict probabilities, not classes\n",
    "        y_prob[test_index] = clf.predict_proba(X_test)\n",
    "        fpr, tpr, thresholds = roc_curve(y[test_index], y_prob[test_index, 1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "    mean_tpr /= len(kf)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, 'k--',label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "    plt.title(title + 'ROC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xfake, yfake = np.random.rand(100,6), np.random.randint(0,2, size=(100,))\n",
    "plt.figure(figsize=(20,16))\n",
    "print (\"Visualize the roc curve of each model\")\n",
    "plot_roc(xfake, yfake, RandomForestClassifier, 'Random_Forest', n_estimators=25, max_features=5)\n",
    "#plot_roc(X, y, LogisticRegression, 'Logistic_Regrssion')\n",
    "#plot_roc(X, y, DecisionTreeClassifier, 'Decision_Tree')\n",
    "#plot_roc(X, y, MultinomialNB, 'Naive_Bayes') error\n",
    "print('\\nPlotting completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Visualize the roc curve of each model\")\n",
    "plot_roc(X, y, RandomForestClassifier, 'Random_Forest', n_estimators=25, max_features=5)\n",
    "plot_roc(X, y, LogisticRegression, 'Logistic_Regrssion')\n",
    "plot_roc(X, y, DecisionTreeClassifier, 'Decision_Tree')\n",
    "#plot_roc(X, y, MultinomialNB, 'Naive_Bayes') error\n",
    "print('\\nPlotting completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
