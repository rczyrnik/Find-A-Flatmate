{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INCLUDES:\n",
    "\n",
    "- LOGISTIC REGRESSION\n",
    "\n",
    "- DECISION TREE CLASSIFIER\n",
    "\n",
    "- RANDOM FOREST CLASSIFIER\n",
    "\n",
    "- GRADIENT BOOSTING CLASSIFIER\n",
    "\n",
    "- ADABOOST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import my_pickle as mp\n",
    "import my_resample as ms\n",
    "import my_functions as mf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# from scipy import interp\n",
    "# from random import *\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "# from sklearn.ensemble.partial_dependence import partial_dependence\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d0c90c151d26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munjson_it\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munjson_it\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'response'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext_similarity_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munjson_it\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_text_similarity'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count_similarity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_similarity_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count_similarity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tfidf_similarity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_similarity_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tfidf_similarity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/coding/Galvanize/MatchingService/my_pickle.py\u001b[0m in \u001b[0;36munjson_it\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munjson_it\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_of_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmy_other_to_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines)\u001b[0m\n\u001b[1;32m    352\u001b[0m         obj = FrameParser(json, orient, dtype, convert_axes, convert_dates,\n\u001b[1;32m    353\u001b[0m                           \u001b[0mkeep_default_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                           date_unit).parse()\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'series'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/json/json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m--> 639\u001b[0;31m                 loads(json, precise_float=self.precise_float), dtype=None)\n\u001b[0m\u001b[1;32m    640\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             decoded = dict((str(k), v)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "X = mp.unjson_it('data_X')\n",
    "y = mp.unjson_it('data_y')['response']\n",
    "text_similarity_df = mp.unjson_it('data_text_similarity')\n",
    "X['count_similarity'] = text_similarity_df['count_similarity']\n",
    "X['tfidf_similarity'] = text_similarity_df['tfidf_similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_similarity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE DATA\n",
    "\n",
    "same train test split, resample, and scaling for everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.as_matrix(), y.as_matrix(), random_state=17)\n",
    "\n",
    "# resample\n",
    "X_train, y_train = ms.oversample(X_train, y_train, .5)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# make fake data\n",
    "pred_all_0 = [0]*len(y_test)\n",
    "pred_all_1 = [1]*len(y_test)\n",
    "pred_50_50 = np.random.choice([0,1], size=len(y_test))\n",
    "pred_90_10 = np.random.choice([0,1], size=len(y_test), p=[.9,.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_importances_trees():\n",
    "    # show feature importances\n",
    "    feature_df = pd.DataFrame([X.columns, model.feature_importances_]).T\n",
    "    feature_df.columns = ['feature','value']\n",
    "    return feature_df.sort_values('value', ascending=False)\n",
    "             \n",
    "def display_metrics():\n",
    "    print(\"\\nMETRICS\")\n",
    "    print(\"Model recall: {}\".format(recall_score(y_test, y_pred)))\n",
    "    print(\"Model precision: {}\".format(precision_score(y_test, y_pred)))\n",
    "    print(\"Model accuracy: {}\".format(model.score(X_test, y_test)))\n",
    "\n",
    "    print (\"\\nCONFUSION MATRIX\")\n",
    "    print (confusion_matrix(y_test, y_pred))\n",
    "    print (\"\\nkey:\")\n",
    "    print (\" TN   FP \")\n",
    "    print (\" FN   TP \")\n",
    "\n",
    "    print(\"\\nRECALL AND ACCURACY FOR DIFFERNET MODELS\")\n",
    "    print(\"recall     \\t precision   \\tmodel\")\n",
    "    print(recall_score(y_test, y_pred), '\\t',precision_score(y_test, y_pred), \"my model\")\n",
    "    print(recall_score(y_test, pred_all_0),'\\t','\\t', precision_score(y_test, pred_all_0), \"\\t\\tpredict all zero\")\n",
    "    print(recall_score(y_test, pred_all_1),'\\t','\\t', precision_score(y_test, pred_all_1), \"predict all one\")\n",
    "    print(recall_score(y_test, pred_50_50),'\\t', precision_score(y_test, pred_50_50), \"predict 50-50\")\n",
    "    print(recall_score(y_test, pred_90_10), precision_score(y_test, pred_90_10), \"predict 90-10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit model\n",
    "# model = RandomForestClassifier(max_depth=50, \n",
    "#                                max_features=None, \n",
    "#                                min_samples_leaf=3, \n",
    "#                                n_estimators=100, \n",
    "#                                n_jobs=-1)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# show metrics\n",
    "display_metrics()\n",
    "\n",
    "# show importances\n",
    "display_importances_trees().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIENT BOOSTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit model\n",
    "model = GradientBoostingClassifier(learning_rate= 0.4, \n",
    "                                   max_depth= 10, \n",
    "                                   min_samples_leaf= 2, \n",
    "                                   min_samples_split= 3, \n",
    "                                   n_estimators= 100, \n",
    "                                   subsample= 1)\n",
    "\n",
    "# model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# show metrics\n",
    "display_metrics()\n",
    "\n",
    "# show importances\n",
    "display_importances_trees().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'display_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cb03e12b63d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# show metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdisplay_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# show importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay_importances_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'display_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "# show metrics\n",
    "display_metrics()\n",
    "\n",
    "# show importances\n",
    "display_importances_trees().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'display_importances_trees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c0dc3983ca04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplay_importances_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'display_importances_trees' is not defined"
     ]
    }
   ],
   "source": [
    "temp_df = display_importances_trees().head(5)\n",
    "plt.bar(temp_df.feature, temp_df.value, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-32ae96e4be15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mX_continuous\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontinuous\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mX_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "binary = ['gender_receiver', 'gender_sender',\n",
    "       'has_about_receiver', 'has_about_sender', 'has_facebookId_receiver',\n",
    "       'has_facebookId_sender', 'has_linkedinId_receiver',\n",
    "       'has_linkedinId_sender', 'has_picture_receiver', 'has_picture_sender',\n",
    "       'has_room_receiver', 'has_room_sender', 'inRelationship_receiver', \n",
    "          'inRelationship_sender', 'isClean_receiver',\n",
    "       'isClean_sender', 'isNight_receiver', 'isNight_sender',\n",
    "       'isStudent_receiver', 'isStudent_sender', 'petsOk_receiver', 'petsOk_sender',\n",
    "          'same_city', 'same_clean', 'same_college',\n",
    "       'same_country', 'same_gender', 'same_metro', 'same_night',\n",
    "       'same_relate', 'same_smoking', 'same_state', 'same_student',\n",
    "       'same_term', 'same_type', 'same_work','smokingOk_receiver', 'smokingOk_sender']\n",
    "\n",
    "continuous = ['I_count_receiver', 'I_count_sender', 'age_dif', 'age_receiver',\n",
    "       'age_sender', 'amenities_overlap', 'distance', 'exclaim_count_receiver',\n",
    "       'exclaim_count_sender','hobbies_overlap','len_about_receiver',\n",
    "       'len_about_sender', 'maxCost_receiver', 'maxCost_sender',\n",
    "       'minCost_receiver', 'minCost_sender', 'neighborhoods_overlap',\n",
    "       'numRoommates_receiver', 'numRoommates_sender', 'period_count_receiver',\n",
    "       'period_count_sender', 'question_count_receiver', 'question_count_sender', 'rent_overlap',\n",
    "       'roommate_similarity','sentence_count_receiver',\n",
    "       'sentence_count_sender', 'term_receiver', 'term_sender', 'type_receiver', 'type_sender',\n",
    "       'urgency_receiver', 'urgency_sender', 'count_similarity',\n",
    "       'tfidf_similarity']\n",
    "\n",
    "\n",
    "X_continuous = X[continuous]\n",
    "X_binary = X[binary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b5ab17e92531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-af1feb1973fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m        'exclaim_count_sender']\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mX_my_fave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmy_fav\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mX_not_me_fav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnot_my_fav\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "my_fav = ['same_city', 'same_clean', 'same_college',\n",
    "       'same_country', 'same_gender', 'same_metro', 'same_night',\n",
    "       'same_relate', 'same_smoking', 'same_state', 'same_student',\n",
    "       'same_term', 'same_type', 'same_work', 'sentence_count_receiver',\n",
    "       'sentence_count_sender', 'tfidf_similarity','urgency_receiver', 'urgency_sender', \n",
    "          'rent_overlap',\n",
    "       'roommate_similarity',  'neighborhoods_overlap',\n",
    "       'numRoommates_receiver', 'numRoommates_sender', 'isStudent_receiver', 'isStudent_sender', 'len_about_receiver',\n",
    "       'len_about_sender', 'has_room_receiver', 'has_room_sender', 'hobbies_overlap','gender_receiver', 'gender_sender',\n",
    "'I_count_receiver', 'I_count_sender', 'age_dif', 'age_receiver',\n",
    "       'age_sender', 'amenities_overlap', 'distance' ]\n",
    "          \n",
    "not_my_fav = ['smokingOk_receiver', 'smokingOk_sender',\n",
    "       'term_receiver', 'term_sender', 'type_receiver', 'type_sender',\n",
    "       'count_similarity', 'period_count_receiver',\n",
    "       'period_count_sender', 'petsOk_receiver', 'petsOk_sender',\n",
    "       'question_count_receiver', 'question_count_sender', 'maxCost_receiver', 'maxCost_sender',\n",
    "       'minCost_receiver', 'minCost_sender',       'inRelationship_receiver', 'inRelationship_sender', 'isClean_receiver',\n",
    "       'isClean_sender', 'isNight_receiver', 'isNight_sender','has_about_receiver', 'has_about_sender', 'has_facebookId_receiver',\n",
    "       'has_facebookId_sender', 'has_linkedinId_receiver',\n",
    "       'has_linkedinId_sender', 'has_picture_receiver', 'has_picture_sender',\n",
    "              'exclaim_count_receiver',\n",
    "       'exclaim_count_sender']\n",
    "\n",
    "X_my_fave = X[my_fav]\n",
    "X_not_me_fav = X[not_my_fav]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f1e5fb85f388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mX_comparisons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomparisons\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "comparisons = ['age_dif','amenities_overlap', 'distance','hobbies_overlap',\n",
    "               'neighborhoods_overlap','rent_overlap',\n",
    "       'roommate_similarity', 'same_city', 'same_clean', 'same_college',\n",
    "       'same_country', 'same_gender', 'same_metro', 'same_night',\n",
    "       'same_relate', 'same_smoking', 'same_state', 'same_student',\n",
    "       'same_term', 'same_type', 'same_work', 'count_similarity',\n",
    "       'tfidf_similarity']\n",
    "not_comparisons = ['I_count_receiver', 'I_count_sender',  'age_receiver',\n",
    "       'age_sender',  'exclaim_count_receiver',\n",
    "       'exclaim_count_sender', 'gender_receiver', 'gender_sender',\n",
    "       'has_about_receiver', 'has_about_sender', 'has_facebookId_receiver',\n",
    "       'has_facebookId_sender', 'has_linkedinId_receiver',\n",
    "       'has_linkedinId_sender', 'has_picture_receiver', 'has_picture_sender',\n",
    "       'has_room_receiver', 'has_room_sender', \n",
    "       'inRelationship_receiver', 'inRelationship_sender', 'isClean_receiver',\n",
    "       'isClean_sender', 'isNight_receiver', 'isNight_sender',\n",
    "       'isStudent_receiver', 'isStudent_sender', 'len_about_receiver',\n",
    "       'len_about_sender', 'maxCost_receiver', 'maxCost_sender',\n",
    "       'minCost_receiver', 'minCost_sender', \n",
    "       'numRoommates_receiver', 'numRoommates_sender', 'period_count_receiver',\n",
    "       'period_count_sender', 'petsOk_receiver', 'petsOk_sender',\n",
    "       'question_count_receiver', 'question_count_sender',  'sentence_count_receiver',\n",
    "       'sentence_count_sender', 'smokingOk_receiver', 'smokingOk_sender',\n",
    "       'term_receiver', 'term_sender', 'type_receiver', 'type_sender',\n",
    "       'urgency_receiver', 'urgency_sender']\n",
    "\n",
    "\n",
    "X_comparisons = X[comparisons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_comparisons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7d43958ccc68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_comparisons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# resample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moversample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_comparisons' is not defined"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_comparisons.as_matrix(), y.as_matrix(), random_state=17)\n",
    "\n",
    "# resample\n",
    "X_train, y_train = ms.oversample(X_train, y_train, .5)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# make fake data\n",
    "pred_all_0 = [0]*len(y_test)\n",
    "pred_all_1 = [1]*len(y_test)\n",
    "pred_50_50 = np.random.choice([0,1], size=len(y_test))\n",
    "pred_90_10 = np.random.choice([0,1], size=len(y_test), p=[.9,.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "METRICS\n",
      "Model recall: 0.5358361774744027\n",
      "Model precision: 0.16354166666666667\n",
      "Model accuracy: 0.6624730409777139\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[1686  803]\n",
      " [ 136  157]]\n",
      "\n",
      "key:\n",
      " TN   FP \n",
      " FN   TP \n",
      "\n",
      "RECALL AND ACCURACY FOR DIFFERNET MODELS\n",
      "recall     \t precision   \tmodel\n",
      "0.535836177474 \t 0.163541666667 my model\n",
      "0.0 \t \t 0.0 \t\tpredict all zero\n",
      "1.0 \t \t 0.105319913731 predict all one\n",
      "0.505119453925 \t 0.106936416185 predict 50-50\n",
      "0.105802047782 0.111510791367 predict 90-10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age_dif</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I_count_receiver</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>inRelationship_receiver</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hobbies_overlap</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amenities_overlap</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature value\n",
       "2                   age_dif  0.32\n",
       "0          I_count_receiver  0.14\n",
       "22  inRelationship_receiver  0.12\n",
       "21          hobbies_overlap  0.08\n",
       "5         amenities_overlap  0.07"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# show metrics\n",
    "display_metrics()\n",
    "\n",
    "# show importances\n",
    "display_importances_trees().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADABOOST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "METRICS\n",
      "Model recall: 0.5290102389078498\n",
      "Model precision: 0.15562248995983935\n",
      "Model accuracy: 0.6480948957584471\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[1648  841]\n",
      " [ 138  155]]\n",
      "\n",
      "key:\n",
      " TN   FP \n",
      " FN   TP \n",
      "\n",
      "RECALL AND ACCURACY FOR DIFFERNET MODELS\n",
      "recall     \t precision   \tmodel\n",
      "0.529010238908 \t 0.15562248996 my model\n",
      "0.0 \t \t 0.0 \t\tpredict all zero\n",
      "1.0 \t \t 0.105319913731 predict all one\n",
      "0.505119453925 \t 0.106936416185 predict 50-50\n",
      "0.105802047782 0.111510791367 predict 90-10\n",
      "CPU times: user 690 ms, sys: 74.7 ms, total: 765 ms\n",
      "Wall time: 966 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit model\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# show metrics\n",
    "display_metrics()\n",
    "\n",
    "# show importances\n",
    "display_importances_trees().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "METRICS\n",
      "Model recall: 0.20477815699658702\n",
      "Model precision: 0.20618556701030927\n",
      "Model accuracy: 0.8332135154565061\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[2258  231]\n",
      " [ 233   60]]\n",
      "\n",
      "key:\n",
      " TN   FP \n",
      " FN   TP \n",
      "\n",
      "RECALL AND ACCURACY FOR DIFFERNET MODELS\n",
      "recall     \t precision   \tmodel\n",
      "0.204778156997 \t 0.20618556701 my model\n",
      "0.0 \t \t 0.0 \t\tpredict all zero\n",
      "1.0 \t \t 0.105319913731 predict all one\n",
      "0.488054607509 \t 0.105379513633 predict 50-50\n",
      "0.0819112627986 0.0948616600791 predict 90-10\n",
      "CPU times: user 356 ms, sys: 25.5 ms, total: 381 ms\n",
      "Wall time: 392 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# show metrics\n",
    "display_metrics()\n",
    "\n",
    "# show importances\n",
    "display_importances_trees().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "METRICS\n",
      "Model recall: 0.0\n",
      "Model precision: 0.0\n",
      "Model accuracy: 0.6409058231488138\n",
      "\n",
      "CONFUSION MATRIX\n",
      "[[2782]]\n",
      "\n",
      "key:\n",
      " TN   FP \n",
      " FN   TP \n",
      "\n",
      "RECALL AND ACCURACY FOR DIFFERNET MODELS\n",
      "recall     \t precision   \tmodel\n",
      "0.0 \t 0.0 my model\n",
      "0.0 \t \t 0.0 \t\tpredict all zero\n",
      "0.0 \t \t 0.0 predict all one\n",
      "0.0 \t 0.0 predict 50-50\n",
      "0.0 0.0 predict 90-10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for abs(): 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Documents/Galvanize/MatchingService/my_functions.py\u001b[0m in \u001b[0;36mdisplay_importances_linear\u001b[0;34m(model, X)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfeature_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfeature_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'feature'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'coefficient'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mfeature_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abs_value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefficient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mfeature_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sign'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefficient\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfeature_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'abs_value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2353\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for abs(): 'NoneType'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# show metrics\n",
    "mf.display_metrics(model, X_test, y_test)\n",
    "\n",
    "# show importances\n",
    "mf.display_importances_linear(model, X).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame([X.columns,model.coef_[0]]).T\n",
    "results_df.columns = ['feature','coefficients']\n",
    "results_df['abs_val'] = results_df.coefficients.apply(abs)\n",
    "results_df['sign'] = results_df.coefficients.apply(lambda s: s>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df.head().sort_values('abs_val', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresh = roc_curve(y_test, y_pred_coef[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot(np.arange(0,1,.001),np.arange(0,1,.001))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_grid_search(X, y):\n",
    "    '''\n",
    "    X as 2d numpy array\n",
    "    y as 1d numpy array\n",
    "    \n",
    "    PARAMETERS\n",
    "    n_estimators: The number of trees in the forest\n",
    "    criterion: gini or entropy\n",
    "    max_features: The number of features to consider when looking for the best split\n",
    "        If int, then consider max_features features at each split.\n",
    "        If float, then max_features is a percentage and int(max_features * n_features) features are considered at each split.\n",
    "        If “auto”, then max_features=sqrt(n_features).\n",
    "        If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).\n",
    "        If “log2”, then max_features=log2(n_features).\n",
    "        If None, then max_features=n_features.\n",
    "    max_depth: The maximum depth of the tree\n",
    "    n_jobs: The number of jobs to run in parallel for both fit and predict. If -1, then the number of jobs is set to the number of cores.\n",
    "    '''\n",
    "    \n",
    "    # Split it up into our training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    # resample\n",
    "    X_train, y_train = ms.oversample(X_train.as_matrix(), y_train.as_matrix(), .5)\n",
    "    \n",
    "    # Initalize our model here\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    # Here are the params we are tuning\n",
    "    param_grid = {'max_features' : [None],\n",
    "                  'n_estimators' : [50,100,1000],\n",
    "                  'max_depth': [50],\n",
    "                  'min_samples_leaf': [3]\n",
    "                  }\n",
    "\n",
    "    # Plug in our model, params dict, and the number of jobs, then .fit()\n",
    "    gs_cv = GridSearchCV(model, param_grid, n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "    # return the best score and the best params\n",
    "    return gs_cv.best_score_, gs_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = RandomForestClassifier(max_depth=50, max_features=None, min_samples_leaf=3, n_estimators=100, n_jobs=-1)\n",
    "fit_model(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n = do_grid_search(X, y)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = LogisticRegression()\n",
    "fit_model(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print (\"    Decision Tree:       \", get_scores(DecisionTreeClassifier, X_train, X_test, y_train, y_test))\n",
    "print (\"    Naive Bayes:         \", get_scores(MultinomialNB, X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the standard deviation for feature importances across all trees\n",
    "\n",
    "n = len(X.columns)\n",
    "\n",
    "#importances = forest_fit.feature_importances_[:n]\n",
    "importances = model.feature_importances_[:n]\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features = list(X.columns[indices])\n",
    "\n",
    "# print(\"Feature ranking:\")\n",
    "# for f in range(n):\n",
    "#     print(\"%d. %s (%f)\" % (f + 1, features[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(n), importances[indices], yerr=std[indices], color=\"r\", align=\"edge\", width = -.9)\n",
    "plt.xticks(range(n), features, rotation=-75)\n",
    "plt.xlim([-1, n])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try modifying the number of trees, graph results\n",
    "num_trees = range(5, 50, 5)\n",
    "accuracies = []\n",
    "for n in num_trees:\n",
    "    tot = 0\n",
    "    for i in range(5):\n",
    "        rf = RandomForestClassifier(n_estimators=n)\n",
    "        rf.fit(X_train, y_train)\n",
    "        tot += rf.score(X_test, y_test)\n",
    "    accuracies.append(tot / 5)\n",
    "plt.plot(num_trees, accuracies)\n",
    "plt.xlabel=\"num_trees\"\n",
    "plt.ylabel=\"accuracy\"\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modifying the max features parameter\n",
    "for nn in range(10):\n",
    "    num_features = range(2, len(X.columns))\n",
    "    accuracies = []\n",
    "    for n in num_features:\n",
    "        tot = 0\n",
    "        for i in range(5):\n",
    "            rf = RandomForestClassifier(max_features=n)\n",
    "            rf.fit(X_train, y_train)\n",
    "            tot += rf.score(X_test, y_test)\n",
    "        accuracies.append(tot / 5)\n",
    "    plt.plot(num_features, accuracies)\n",
    "    plt.xlabel=\"num_features\"\n",
    "    plt.ylabel=\"accuracy\"\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run all the other classifiers that we have learned so far in class\n",
    "def get_scores(classifier, X_train, X_test, y_train, y_test, **kwargs):\n",
    "    model = classifier(**kwargs)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    return model.score(X_test, y_test), \\\n",
    "           precision_score(y_test, y_predict), \\\n",
    "           recall_score(y_test, y_predict)\n",
    "\n",
    "print (\"    Model,                Accuracy, Precision, Recall\")\n",
    "print (\"    Random Forest:       \", get_scores(RandomForestClassifier, X_train, X_test, y_train, y_test, n_estimators=25, max_features=5))\n",
    "print (\"    Logistic Regression: \", get_scores(LogisticRegression, X_train, X_test, y_train, y_test))\n",
    "print (\"    Decision Tree:       \", get_scores(DecisionTreeClassifier, X_train, X_test, y_train, y_test))\n",
    "print (\"    Naive Bayes:         \", get_scores(MultinomialNB, X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc(X, y, clf_class, title, **kwargs):\n",
    "# def plot_roc(X, y, clf_class, kwargs):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    kf = KFold(len(y), n_folds=5, shuffle=True)\n",
    "    y_prob = np.zeros((len(y),2))\n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    all_tpr = []\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        # Predict probabilities, not classes\n",
    "        y_prob[test_index] = clf.predict_proba(X_test)\n",
    "        fpr, tpr, thresholds = roc_curve(y[test_index], y_prob[test_index, 1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "    mean_tpr /= len(kf)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, 'k--',label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "    plt.title(title + 'ROC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xfake, yfake = np.random.rand(100,6), np.random.randint(0,2, size=(100,))\n",
    "plt.figure(figsize=(20,16))\n",
    "print (\"Visualize the roc curve of each model\")\n",
    "plot_roc(xfake, yfake, RandomForestClassifier, 'Random_Forest', n_estimators=25, max_features=5)\n",
    "#plot_roc(X, y, LogisticRegression, 'Logistic_Regrssion')\n",
    "#plot_roc(X, y, DecisionTreeClassifier, 'Decision_Tree')\n",
    "#plot_roc(X, y, MultinomialNB, 'Naive_Bayes') error\n",
    "print('\\nPlotting completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Visualize the roc curve of each model\")\n",
    "plot_roc(X, y, RandomForestClassifier, 'Random_Forest', n_estimators=25, max_features=5)\n",
    "plot_roc(X, y, LogisticRegression, 'Logistic_Regrssion')\n",
    "plot_roc(X, y, DecisionTreeClassifier, 'Decision_Tree')\n",
    "#plot_roc(X, y, MultinomialNB, 'Naive_Bayes') error\n",
    "print('\\nPlotting completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "feature_importances = np.argsort(model.feature_importances_)\n",
    "top_n = 10\n",
    "print(\"\\nFEATURE RANKINGS\")\n",
    "for n in range(top_n):\n",
    "    print(n+1, '\\t',X.columns[feature_importances[-n-1]], '\\t',sorted(model.feature_importances_)[-n-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show feature importances\n",
    "feature_df = display_feature_importances()\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_features = list(feature_df.sort_values('value', ascending=False).index)\n",
    "for feature in top_features[:6]:\n",
    "#     print(type(feature))\n",
    "    fig, axs = plot_partial_dependence(model, X_train, [feature], X.columns) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAHWCAYAAABXF6HSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wCX7UXOZl3ReAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a15f42c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "r = []\n",
    "p = []\n",
    "for w in np.arange(.1,.9,.1):\n",
    "    fake_pred = np.random.choice([0,1], size=len(y_test), p=[w,1-w])\n",
    "    r.append(recall_score(y_test, fake_pred))\n",
    "    p.append(precision_score(y_test, fake_pred))\n",
    "             \n",
    "             \n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(p, r)\n",
    "plt.axis([0, 1, 0,1])\n",
    "# plt.title('for min_samples_split in [.1,.3,.5,.7,.9,2,3,4]:')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
