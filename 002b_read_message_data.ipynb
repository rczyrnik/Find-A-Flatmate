{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filepath\n",
    "data_file_path = \"/Users/gandalf/Documents/coding/do_not_commit/capstone/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataframe\n",
    "message_filename = data_file_path + \"raw_data_messages.json\"\n",
    "DF = pd.read_json(message_filename)\n",
    "print(\"... read in dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy\n",
    "df = DF.copy()\n",
    "df = df[24:]\n",
    "print(\"... created a copy and cropped odd convos from start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into conversation and last message dataframes\n",
    "df['conv_flag'] = df.conversations.apply(lambda x: 1 if isinstance(x, dict) else 0)\n",
    "df = df[df.conv_flag==1].drop(['users','conv_flag'],axis=1)\n",
    "# users_df = df[df.conv_flag==0].drop(['conversations','conv_flag'],axis=1)\n",
    "print(\"... got just conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get conversation length\n",
    "df['len_convo'] = df.conversations.apply(len)\n",
    "print(\"... got conversation lengths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all possible column headings (#oneliners)\n",
    "master_set = set()\n",
    "for s in df.conversations.apply(lambda x: set(list(x.values())[0].keys())).tolist(): master_set = master_set.union(s) \n",
    "\n",
    "def get_deets_fn(x,label):\n",
    "    try: return list(x.values())[0][label]\n",
    "    except: return None\n",
    "    \n",
    "column_headings = list(master_set)\n",
    "\n",
    "for heading in column_headings:\n",
    "    df['first_message_' + heading] = df.conversations.apply(lambda x: get_deets_fn(x,heading))\n",
    "print(\"... got details from the first message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is really gross, but has a kinda nifty end if you're willing to invest the time\n",
    "\n",
    "df['indexies'] = df.index\n",
    "df['first_ten'] = df.indexies.apply(lambda x: x[:10])\n",
    "df['second_ten'] = df.indexies.apply(lambda x: x[10:])\n",
    "df['is_first'] = df.first_message_uid == df['first_ten']\n",
    "df['is_second'] = df.first_message_uid == df['second_ten']\n",
    "df['second_message_uid'] = df.is_second*df.first_ten + df.is_first*df.second_ten\n",
    "\n",
    "print(\"... added second message uid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill blank conversation with empty strings\n",
    "df.first_message_text = df.first_message_text.fillna('')\n",
    "\n",
    "# get len of message text\n",
    "df['first_message_len'] = df.first_message_text.apply(len)\n",
    "print(\"... got the length of the first message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other cleanup\n",
    "df.first_message_timestamp = \\\n",
    "    df.first_message_timestamp.apply(lambda x: \n",
    "                                           pd.to_datetime(x*1000000) \n",
    "                                           if isinstance(x, int) \n",
    "                                           else x)\n",
    "print(\"... converted timestamp to datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_message_date'] = df.first_message_timestamp.apply(lambda x: x.date())\n",
    "\n",
    "df['first_message_year'] = df.first_message_timestamp.apply(lambda x: x.year)\n",
    "df['first_message_day_of_year'] = df.first_message_timestamp.apply(lambda x: int(x.strftime('%j')))\n",
    "\n",
    "df['first_message_month'] = df.first_message_timestamp.apply(lambda x: x.month)\n",
    "df['first_message_day_of_month'] = df.first_message_timestamp.apply(lambda x: x.day)\n",
    "\n",
    "df['first_message_week'] = df.first_message_timestamp.apply(lambda x: x.isocalendar()[1])\n",
    "df['first_message_day_of_week'] = df.first_message_timestamp.apply(lambda x: x.isoweekday())\n",
    "\n",
    "df['first_message_day'] = df.first_message_timestamp.apply(lambda x: x.toordinal())\n",
    "df['first_message_hour'] = df.first_message_timestamp.apply(lambda x: x.hour)\n",
    "\n",
    "print(\"... broke down time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start droppin\n",
    "col_to_drop = ['conversations','indexies','first_ten','second_ten','is_first','is_second', 'first_message_emailed',\n",
    "       'first_message_imageURL', 'first_message_emailAttempted',]\n",
    "# df = df.drop(col_to_drop,axis=1)\n",
    "# print(\"... dropped a bunch of lame columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange columns\n",
    "df = df[['first_message_uid', 'second_message_uid',\n",
    "                     'len_convo', 'first_message_read',\n",
    "                     'first_message_timestamp', \n",
    "                     'first_message_text', 'first_message_len', 'first_message_date',\n",
    "                     'first_message_year', 'first_message_day_of_year',\n",
    "                       'first_message_month', 'first_message_day_of_month',\n",
    "                       'first_message_week', 'first_message_day_of_week', 'first_message_day',\n",
    "                       'first_message_hour']]\n",
    "print(\"... rearranged remaining columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIMIT ANALYSIS TO MESSAGES BETWEEN MAR 1, 2017 and SEPT 30, 2017\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.first_message_month < 10]\n",
    "df = df[df.first_message_month > 2]\n",
    "print(min(df.first_message_timestamp))\n",
    "print(max(df.first_message_timestamp))\n",
    "print(\"... cropped date to Jan through Sept 2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Constant for the lols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['const2'] = 1\n",
    "print(\"... added constant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD RESPONSE COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['response'] = df.len_convo.apply(lambda x: 1 if x > 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE AS JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(data_file_path+'convo_df.json')\n",
    "print(\"... saved as json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SAVE AS PICKLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(data_file_path + 'convo_df.pkl')\n",
    "print(\"... saved as pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
