{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_pickle as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = mp.unjson_it('data_user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_kmeans(df_data, k, vectorizer):\n",
    "    #Vector text\n",
    "    X = vectorizer.fit_transform(df_data)\n",
    "\n",
    "    #Vector text counts\n",
    "    matrix_counts = X.toarray()\n",
    "\n",
    "    #fit kmeans model\n",
    "    kmeans = KMeans(n_clusters = k).fit(X)\n",
    "\n",
    "    #get feature names\n",
    "    fnames = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "    #Get length of labels return\n",
    "    print (\"No. of reports {} \\n\".format(kmeans.labels_.shape[0]))\n",
    "\n",
    "    labels = [fnames[np.argsort(kmeans.cluster_centers_[i])[-50:]] for i in range(0,k)]\n",
    "\n",
    "    for i in range(0,k):\n",
    "        print (\"Words: \\n\")\n",
    "        print(i, labels[i], '\\n\\n')\n",
    "\n",
    "    fname_scores = pd.DataFrame(pd.DataFrame(matrix_counts, columns=fnames).sum())\n",
    "    fname_scores[0] = round(fname_scores[0]*100,0).astype(int)            \n",
    "\n",
    "\n",
    "    return kmeans, fname_scores.sort_values(0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=1, \n",
    "                             min_df=0, \n",
    "                             stop_words='english', \n",
    "                             max_features = 10000,\n",
    "                             ngram_range =(1,2),\n",
    "                             norm = 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_kmeans(df.about, 2, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(user_df['about'])\n",
    "features = vectorizer.get_feature_names()\n",
    "kmeans = KMeans()\n",
    "kmeans.fit(X)\n",
    "\n",
    "top_centroids = kmeans.cluster_centers_.argsort()[:,-1:-11:-1]\n",
    "print(\"top features for each cluster:\")\n",
    "for num, centroid in enumerate(top_centroids):\n",
    "    print(\"%d: %s\" % (num, \", \".join(features[i] for i in centroid)))\n",
    "    \n",
    "%%time\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X = vectorizer.fit_transform(user_df['about'])\n",
    "features = vectorizer.get_feature_names()\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "top_centroids = kmeans.cluster_centers_.argsort()[:,-1:-11:-1]\n",
    "print (\"top features for each cluster with 1000 max features:\")\n",
    "for num, centroid in enumerate(top_centroids):\n",
    "    print(\"%d: %s\" % (num, \", \".join(features[i] for i in centroid)))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
