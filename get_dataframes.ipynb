{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIRST DATA FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/gandalf/Documents/data/data_users.csv\"\n",
    "\n",
    "user_df = pd.read_csv(filename, parse_dates=['created', \n",
    "                                        'updated', \n",
    "                                        'available', \n",
    "                                        'birthday', \n",
    "                                        'lastActive'])\n",
    "\n",
    "user_df = user_df.fillna({'legacyId' : 'None',\n",
    "                'about'    : '', \n",
    "                'birthday' : pd.to_datetime('1899-01-01'), \n",
    "                'latitude' : 0, \n",
    "                'longitude': 0})\n",
    "\n",
    "user_df['len_about'] = user_df.about.apply(lambda x: len(x))\n",
    "user_df['uid'] = user_df.legacyId\n",
    "col_to_drop = ['id','legacyId','hashedPassword','email','firstName','lastName','username']\n",
    "user_df = user_df.drop(col_to_drop, axis=1)\n",
    "\n",
    "user_df = user_df[['uid', 'created', 'updated', 'about', 'len_about', 'available',\n",
    "       'birthday', 'collegeId', 'emailVerified', 'foundRoommate', 'gender',\n",
    "       'groupChat', 'hometownId', 'inRelationship', 'isClean', 'isNight',\n",
    "       'isStudent', 'lastActive', 'latitude', 'longitude', 'maxCost',\n",
    "       'minCost', 'numRoommates', 'onboarded', 'petsOk', 'pictureId',\n",
    "       'roomPostId', 'roomTypeId', 'smokingOk', 'term', 'work']]\n",
    "\n",
    "user_df = user_df.drop_duplicates()\n",
    "user_df = user_df.set_index('uid')\n",
    "user_df.head(2)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Don't pickle here, pickle later '''\n",
    "\n",
    "# path_users = \"/Users/gandalf/Documents/data/data_users.pkl\"\n",
    "# user_df.to_pickle(path_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# SECOND DATA FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"/Users/gandalf/Documents/data/data_messages.json\"\n",
    "json_data=open(filename).read()\n",
    "data = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create first data frame (all messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['message_id',       # Added, unique for each row\n",
    "               'conversation_id',   # Added, identifies the conversation, not unique\n",
    "               'uid',               # message sender\n",
    "               'read',              # true/false value\n",
    "               'readBy',            # message recipient(s)\n",
    "               'text_length',       # Added, length of text\n",
    "               'timestamp',         # time\n",
    "               'imageURL',          # image url\n",
    "               'emailAttempted',    # ?\n",
    "               'emailed']           # ?\n",
    "\n",
    "mi,ci,ui,rd,rb,tl,ts,iu,ea,em = [],[],[],[],[],[],[],[],[],[]\n",
    "\n",
    "for conversation_id, conversation_data in data[\"conversations\"].items():\n",
    "    for message_id, message_data in conversation_data.items():\n",
    "        information = defaultdict(lambda: '', message_data)\n",
    "        ci.append(conversation_id)\n",
    "        mi.append(message_id)\n",
    "        ui.append(information['uid'])\n",
    "        rd.append(information['read'])\n",
    "        rb.append(information['readBy'])\n",
    "        tl.append(len(information['text'].split()))\n",
    "        ts.append(information['timestamp'])\n",
    "        iu.append(information['imageURL'])\n",
    "        ea.append(information['emailAttempted'])\n",
    "        em.append(information['emailed'])\n",
    "\n",
    "message_df = pd.DataFrame([mi,ci,ui,rd,rb,tl,ts,iu,ea,em]).T\n",
    "message_df.columns=column_names\n",
    "\n",
    "message_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle first data frame (all messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_message = \"/Users/gandalf/Documents/data/data_message.pkl\"\n",
    "message_df.to_pickle(path_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create second data frame (last messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['user_id',       # user id\n",
    "               'first_ten',      # first ten of the 20 digit key\n",
    "               'last_ten',       # last ten of the 20 digit key (prob userid)\n",
    "               'lastMessageId']  # message id\n",
    "\n",
    "ui,ft,lt,lm = [],[],[],[]\n",
    "\n",
    "for user_id, user_data in data['users'].items():\n",
    "    for key, value in user_data['conversations'].items():\n",
    "        ui.append(user_id)\n",
    "        ft.append(key[:10])\n",
    "        lt.append(key[10:])\n",
    "        lm.append(value['lastMessageId'])\n",
    "\n",
    "lastmessage_df = pd.DataFrame([ui,ft,lt,lm]).T\n",
    "lastmessage_df.columns=column_names\n",
    "\n",
    "lastmessage_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle second data frame (last messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_lastmessage = \"/Users/gandalf/Documents/data/data_lastmessage.pkl\"\n",
    "lastmessage_df.to_pickle(path_lastmessage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create third data frame (response df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_df['const'] = 1\n",
    "convo_length = message_df.groupby('conversation_id').const.sum().T.to_dict()\n",
    "\n",
    "column_names = ['conv_id',       # user id\n",
    "                'response',      # did anyone respond?\n",
    "                'first_uid',     # user who sent the first message\n",
    "                'first_mid',     # message id of the first message\n",
    "                'second_uid',    # user who responded\n",
    "                'second_mid']    # message id of the second message\n",
    "\n",
    "ci,rs,fu,fm,su,sm = [],[],[],[],[],[]\n",
    "already_added = set()\n",
    "\n",
    "first_message = True\n",
    "second_message = False\n",
    "        \n",
    "for index, row in message_df.iterrows():\n",
    "    if convo_length[row.conversation_id] == 1:\n",
    "        ci.append(row.conversation_id)\n",
    "        rs.append(False)\n",
    "        fu.append(row.uid)\n",
    "        fm.append(row.message_id)\n",
    "        su.append(None)\n",
    "        sm.append(None)\n",
    "        \n",
    "    elif row.conversation_id not in already_added:\n",
    "        if first_message:\n",
    "            ci.append(row.conversation_id)\n",
    "            rs.append(True)\n",
    "            fu.append(row.uid)\n",
    "            fm.append(row.message_id)\n",
    "            first_message = False\n",
    "            second_message = True\n",
    "        elif second_message:\n",
    "            su.append(row.uid)\n",
    "            sm.append(row.message_id)\n",
    "            already_added.add(row.conversation_id)\n",
    "            first_message = True\n",
    "            second_message = False\n",
    "\n",
    "response_df = pd.DataFrame([ci,rs,fu,fm,su,sm]).T\n",
    "response_df.columns=column_names\n",
    "response_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle third data frame (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_response = \"/Users/gandalf/Documents/data/data_response.pkl\"\n",
    "response_df.to_pickle(path_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMBINE DATA FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df['const'] = 1\n",
    "messages_sent_by_user = response_df.groupby('first_uid').const.sum()\n",
    "messages_responded_by_user = response_df[response_df.response == True].groupby('first_uid').const.sum()\n",
    "messages_response_rate_by_user = messages_responded_by_user/messages_sent_by_user\n",
    "\n",
    "user_response = pd.concat([messages_sent_by_user, messages_responded_by_user,messages_response_rate_by_user], axis=1)\n",
    "user_response.columns=[['sent','responses','ratio']]\n",
    "user_response = user_response.fillna(0)\n",
    "\n",
    "user_df = user_df.join(user_response)\n",
    "user_df = user_df.fillna({'sent' : 0,'responses'    : 0, 'ratio' :0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_users = \"/Users/gandalf/Documents/data/data_users.pkl\"\n",
    "user_df.to_pickle(path_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INVESTIGATE A CONVERSATION BY ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_id = 'put id here'\n",
    "\n",
    "for conversation_id, conversation_data in data[\"conversations\"].items():\n",
    "    if conversation_id == convo_id:\n",
    "        for message_id, message_data in conversation_data.items():\n",
    "            information = defaultdict(lambda: '', message_data)\n",
    "            print(information['text'])\n",
    "            \n",
    "message_df[message_df.conversation_id == convo_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
